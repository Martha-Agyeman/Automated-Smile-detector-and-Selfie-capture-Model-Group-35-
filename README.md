# Automated-Smile-detector-and-Selfie-capture-Model-Group-35-
A deep learning model and application that processes live video feed, detects the facial expression and allows a user to capture a photo once a smile is detected. 


The deep learning model utilizes Convolutional neural netweorks for image processing and predicts whether a user is smiling or not. The .ipynb file for the implementation of the model is included in this repository, and when run creates a model for smile prediction. The HTML and JavaScript code is also provided for a web application for smile detection through a live video feed. Designed to be clean, simple and centered, the application features a light gray background and readable font, a live video feed, a "Capture Photo" button, a section for taking pictures, saving, and downloading, a capture action, a "Save Picture" button, and a download link. The JavaScript code includes functionality to capture a photo when the form is submitted, and the captured photo is displayed on a canvas element below the video feed. Here is a link to see the application running: 




To implement, the files must be downloaded an opened in one foler in a python friendly IDE for processing and to create the model for testing. If you are unsure of the processing power of you device, it is best to use Google colab or any cloud based IDE to run to model. The flask implementation of the web application is also included

The application is designed to be responsive, adapting to different screen sizes. Users can capture a photo, save it, and download it using the respective buttons. The application provides a foundation for further development and improvements on the captured photo. 
